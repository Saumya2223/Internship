{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e9d00b",
   "metadata": {},
   "source": [
    "# Assignment - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141431f",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3f552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Header Tag\n",
      "0                       Main Page\n",
      "1            Welcome to Wikipedia\n",
      "2   From today's featured article\n",
      "3                Did you know ...\n",
      "4                     In the news\n",
      "5                     On this day\n",
      "6      From today's featured list\n",
      "7        Today's featured picture\n",
      "8        Other areas of Wikipedia\n",
      "9     Wikipedia's sister projects\n",
      "10            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "header_tags = []\n",
    "for header in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "    header_tags.append(header.text)\n",
    "\n",
    "header_tags_df = pd.DataFrame(header_tags, columns=[\"Header Tag\"])\n",
    "print(header_tags_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370b1cb",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "259bf9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Name Rating Year of release\n",
      "0                            The Shawshank Redemption    9.2            1994\n",
      "1                                       The Godfather    9.2            1972\n",
      "2                                     The Dark Knight    9.0            2008\n",
      "3                               The Godfather Part II    9.0            1974\n",
      "4                                        12 Angry Men    9.0            1957\n",
      "5                                    Schindler's List    8.9            1993\n",
      "6       The Lord of the Rings: The Return of the King    8.9            2003\n",
      "7                                        Pulp Fiction    8.8            1994\n",
      "8   The Lord of the Rings: The Fellowship of the Ring    8.8            2001\n",
      "9                     Il buono, il brutto, il cattivo    8.8            1966\n",
      "10                                       Forrest Gump    8.8            1994\n",
      "11                                         Fight Club    8.7            1999\n",
      "12              The Lord of the Rings: The Two Towers    8.7            2002\n",
      "13                                          Inception    8.7            2010\n",
      "14                            The Empire Strikes Back    8.7            1980\n",
      "15                                         The Matrix    8.7            1999\n",
      "16                                         GoodFellas    8.7            1990\n",
      "17                    One Flew Over the Cuckoo's Nest    8.6            1975\n",
      "18                                              Se7en    8.6            1995\n",
      "19                               Shichinin no samurai    8.6            1954\n",
      "20                              It's a Wonderful Life    8.6            1946\n",
      "21                           The Silence of the Lambs    8.6            1991\n",
      "22                                     Cidade de Deus    8.6            2002\n",
      "23                                Saving Private Ryan    8.6            1998\n",
      "24                                       Interstellar    8.6            2014\n",
      "25                                    La vita è bella    8.6            1997\n",
      "26                                     The Green Mile    8.6            1999\n",
      "27                                          Star Wars    8.5            1977\n",
      "28                         Terminator 2: Judgment Day    8.5            1991\n",
      "29                                 Back to the Future    8.5            1985\n",
      "30                      Sen to Chihiro no kamikakushi    8.5            2001\n",
      "31                                        The Pianist    8.5            2002\n",
      "32                                             Psycho    8.5            1960\n",
      "33                                       Gisaengchung    8.5            2019\n",
      "34                                               Léon    8.5            1994\n",
      "35                                      The Lion King    8.5            1994\n",
      "36                                          Gladiator    8.5            2000\n",
      "37                                 American History X    8.5            1998\n",
      "38                                       The Departed    8.5            2006\n",
      "39                                 The Usual Suspects    8.5            1995\n",
      "40                                       The Prestige    8.5            2006\n",
      "41                                           Whiplash    8.5            2014\n",
      "42                                         Casablanca    8.5            1942\n",
      "43                                     Hotaru no haka    8.5            1988\n",
      "44                                            Seppuku    8.5            1962\n",
      "45                                   The Intouchables    8.5            2011\n",
      "46                                       Modern Times    8.4            1936\n",
      "47                       Once Upon a Time in the West    8.4            1968\n",
      "48                                        Rear Window    8.4            1954\n",
      "49                              Nuovo Cinema Paradiso    8.4            1988\n",
      "50                                              Alien    8.4            1979\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "for movie in soup.find_all(\"td\", class_=\"titleColumn\"):\n",
    "    name = movie.find(\"a\").text\n",
    "    year = movie.find(\"span\").text[1:-1]\n",
    "    rating = movie.find_next_sibling(\"td\", class_=\"ratingColumn\").find(\"strong\").text\n",
    "    movies.append([name, rating, year])\n",
    "\n",
    "movies_df = pd.DataFrame(movies, columns=[\"Name\", \"Rating\", \"Year of release\"])\n",
    "movies_df50 = movies_df[0:51]\n",
    "print(movies_df50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b19e15",
   "metadata": {},
   "source": [
    "# 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4359ab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Name Rating Year of release\n",
      "0   Ramayana: The Legend of Prince Rama    8.5            1993\n",
      "1            Rocketry: The Nambi Effect    8.4            2022\n",
      "2                              Gol Maal    8.4            1979\n",
      "3                               Nayakan    8.4            1987\n",
      "4                            Anbe Sivam    8.4            2003\n",
      "5                           777 Charlie    8.4            2022\n",
      "6                              Jai Bhim    8.4            2021\n",
      "7                     Pariyerum Perumal    8.4            2018\n",
      "8                              3 Idiots    8.4            2009\n",
      "9                           Apur Sansar    8.4            1959\n",
      "10                     Manichitrathazhu    8.4            1993\n",
      "11                                #Home    8.3            2021\n",
      "12                      Soorarai Pottru    8.3            2020\n",
      "13                         Black Friday    8.3            2004\n",
      "14                    Kumbalangi Nights    8.3            2019\n",
      "15                    C/o Kancharapalem    8.3            2018\n",
      "16                     Taare Zameen Par    8.3            2007\n",
      "17                             Kireedam    8.3            1989\n",
      "18                               Dangal    8.3            2016\n",
      "19                               Kaithi    8.3            2019\n",
      "20                               Jersey    8.3            2019\n",
      "21                                   96    8.3            2018\n",
      "22                          Maya Bazaar    8.2            1957\n",
      "23                            Natsamrat    8.2            2016\n",
      "24                               Asuran    8.2            2019\n",
      "25                           Drishyam 2    8.2            2021\n",
      "26                           Sita Ramam    8.2            2022\n",
      "27                         Thevar Magan    8.2            1992\n",
      "28                           Visaaranai    8.2            2015\n",
      "29                  Sarpatta Parambarai    8.2            2021\n",
      "30                           Thalapathi    8.2            1991\n",
      "31                      Pather Panchali    8.2            1955\n",
      "32                         Nadodikkattu    8.2            1987\n",
      "33                             Drishyam    8.2            2013\n",
      "34                   Jaane Bhi Do Yaaro    8.2            1983\n",
      "35                         Thani Oruvan    8.2            2015\n",
      "36                         Sardar Udham    8.2            2021\n",
      "37                            Aparajito    8.2            1956\n",
      "38                         Vada Chennai    8.2            2018\n",
      "39                    Khosla Ka Ghosla!    8.2            2006\n",
      "40                              Anniyan    8.1            2005\n",
      "41                             Ratsasan    8.1            2018\n",
      "42                        Chupke Chupke    8.1            1975\n",
      "43                   Gangs of Wasseypur    8.1            2012\n",
      "44                              Peranbu    8.1            2018\n",
      "45                             Drishyam    8.1            2015\n",
      "46                             Mahanati    8.1            2018\n",
      "47                       Bangalore Days    8.1            2014\n",
      "48                                Satya    8.1            1998\n",
      "49          Agent Sai Srinivasa Athreya    8.1            2019\n",
      "50                               Premam    8.1            2015\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/india/top-rated-indian-movies/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "for movie in soup.find_all(\"td\", class_=\"titleColumn\"):\n",
    "    name = movie.find(\"a\").text\n",
    "    year = movie.find(\"span\").text[1:-1]\n",
    "    rating = movie.find_next_sibling(\"td\", class_=\"ratingColumn\").find(\"strong\").text\n",
    "    movies.append([name, rating, year])\n",
    "\n",
    "movies_idf = pd.DataFrame(movies, columns=[\"Name\", \"Rating\", \"Year of release\"])\n",
    "ind_movies_df50 = movies_idf[0:51]\n",
    "print(ind_movies_df50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7b5ab",
   "metadata": {},
   "source": [
    "# 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c11dd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name  \\\n",
      "0           Shri Ram Nath Kovind   \n",
      "1          Shri Pranab Mukherjee   \n",
      "2   Smt Pratibha Devisingh Patil   \n",
      "3         DR. A.P.J. Abdul Kalam   \n",
      "4           Shri K. R. Narayanan   \n",
      "5        Dr Shankar Dayal Sharma   \n",
      "6            Shri R Venkataraman   \n",
      "7               Giani Zail Singh   \n",
      "8      Shri Neelam Sanjiva Reddy   \n",
      "9       Dr. Fakhruddin Ali Ahmed   \n",
      "10  Shri Varahagiri Venkata Giri   \n",
      "11              Dr. Zakir Husain   \n",
      "12  Dr. Sarvepalli Radhakrishnan   \n",
      "13           Dr. Rajendra Prasad   \n",
      "\n",
      "                                       Term of Office  \n",
      "0                     25 July, 2017 to 25 July, 2022   \n",
      "1                     25 July, 2012 to 25 July, 2017   \n",
      "2                     25 July, 2007 to 25 July, 2012   \n",
      "3                     25 July, 2002 to 25 July, 2007   \n",
      "4                     25 July, 1997 to 25 July, 2002   \n",
      "5                     25 July, 1992 to 25 July, 1997   \n",
      "6                     25 July, 1987 to 25 July, 1992   \n",
      "7                     25 July, 1982 to 25 July, 1987   \n",
      "8                     25 July, 1977 to 25 July, 1982   \n",
      "9                24 August, 1974 to 11 February, 1977  \n",
      "10  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
      "11                        13 May, 1967 to 3 May, 1969  \n",
      "12                       13 May, 1962 to 13 May, 1967  \n",
      "13                   26 January, 1950 to 13 May, 1962  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "presidents = []\n",
    "for president in soup.find_all('div', class_='presidentListing'):\n",
    "    Name = president.find('h3').text\n",
    "    Sname = Name.split(' (')[0]\n",
    "    term = president.find('p').text\n",
    "    Sterm = term.split(': ')[1]\n",
    "    presidents.append([Sname,Sterm])\n",
    "presidents\n",
    "presidents_df = pd.DataFrame(presidents, columns=[\"Name\", \"Term of Office\"])\n",
    "print(presidents_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3863f37",
   "metadata": {},
   "source": [
    "# 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c0809",
   "metadata": {},
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c682c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points Ratings\n",
      "1         India IND      44  5,010     114\n",
      "2     Australia AUS      32  3,572     112\n",
      "3    New Zealand NZ      29  3,229     111\n",
      "4       England ENG      33  3,656     111\n",
      "5      Pakistan PAK      25  2,649     106\n",
      "6   South Africa SA      27  2,775     103\n",
      "7    Bangladesh BAN      33  3,129      95\n",
      "8      Sri Lanka SL      34  2,976      88\n",
      "9   Afghanistan AFG      20  1,419      71\n",
      "10   West Indies WI      41  2,902      71\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "for row in table.find_all(\"tr\")[1:11]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    teams.append(cols[1].text.strip())\n",
    "    matches.append(cols[2].text.strip())\n",
    "    points.append(cols[3].text.strip())\n",
    "    ratings.append(cols[4].text.strip())\n",
    "data = {\n",
    "    \"Team\": teams,\n",
    "    \"Matches\": matches,\n",
    "    \"Points\": points,\n",
    "    \"Ratings\": ratings\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.replace(r'\\n',' ', regex=True)\n",
    "df.index = df.index + 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f4ab7",
   "metadata": {},
   "source": [
    "# b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62b374de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Player Team Ratings\n",
      "1              Babar Azam  PAK     887\n",
      "2   Rassie van der Dussen   SA     787\n",
      "3            David Warner  AUS     747\n",
      "4         Quinton de Kock   SA     743\n",
      "5             Imam-ul-Haq  PAK     740\n",
      "6            Shubman Gill  IND     734\n",
      "7             Virat Kohli  IND     727\n",
      "8             Steve Smith  AUS     719\n",
      "9            Rohit Sharma  IND     719\n",
      "10        Kane Williamson   NZ     700\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "Playername = []\n",
    "Team = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "for row in table.find_all(\"tr\")[1:11]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    Playername.append(cols[1].text.strip())\n",
    "    Team.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "data = {\n",
    "    \"Player\": Playername,\n",
    "    \"Team\": Team,\n",
    "    \"Ratings\": ratings\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.index = df.index + 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b818a02",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b5701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Player Team Ratings\n",
      "1      Mohammed Siraj  IND     729\n",
      "2      Josh Hazlewood  AUS     727\n",
      "3         Trent Boult   NZ     708\n",
      "4      Mitchell Starc  AUS     665\n",
      "5         Rashid Khan  AFG     659\n",
      "6          Adam Zampa  AUS     655\n",
      "7     Shakib Al Hasan  BAN     652\n",
      "8      Shaheen Afridi  PAK     641\n",
      "9   Mustafizur Rahman  BAN     638\n",
      "10   Mujeeb Ur Rahman  AFG     637\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "Playername = []\n",
    "Team = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "for row in table.find_all(\"tr\")[1:11]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    Playername.append(cols[1].text.strip())\n",
    "    Team.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "data = {\n",
    "    \"Player\": Playername,\n",
    "    \"Team\": Team,\n",
    "    \"Ratings\": ratings\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.index = df.index + 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07818fd",
   "metadata": {},
   "source": [
    "# 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7909a5",
   "metadata": {},
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f101e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points Ratings\n",
      "1     Australia AUS      21  3,603     172\n",
      "2       England ENG      28  3,342     119\n",
      "3   South Africa SA      26  3,098     119\n",
      "4         India IND      27  2,820     104\n",
      "5    New Zealand NZ      25  2,553     102\n",
      "6    West Indies WI      27  2,535      94\n",
      "7    Bangladesh BAN      13    983      76\n",
      "8      Thailand THA       8    572      72\n",
      "9      Pakistan PAK      27  1,678      62\n",
      "10     Sri Lanka SL       8    353      44\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "for row in table.find_all(\"tr\")[1:11]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    teams.append(cols[1].text.strip())\n",
    "    matches.append(cols[2].text.strip())\n",
    "    points.append(cols[3].text.strip())\n",
    "    ratings.append(cols[4].text.strip())\n",
    "data = {\n",
    "    \"Team\": teams,\n",
    "    \"Matches\": matches,\n",
    "    \"Points\": points,\n",
    "    \"Ratings\": ratings\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.replace(r'\\n',' ', regex=True)\n",
    "df.index = df.index + 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98bdce",
   "metadata": {},
   "source": [
    "# b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc097387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Ratings\n",
       "0         Alyssa Healy  AUS     762\n",
       "1          Beth Mooney  AUS     754\n",
       "2      Laura Wolvaardt   SA     732\n",
       "3       Natalie Sciver  ENG     731\n",
       "4          Meg Lanning  AUS     717\n",
       "5     Harmanpreet Kaur  IND     716\n",
       "6      Smriti Mandhana  IND     714\n",
       "7       Rachael Haynes  AUS     680\n",
       "8  Chamari Athapaththu   SL     655\n",
       "9    Amy Satterthwaite   NZ     641"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "Playername = []\n",
    "Team = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "for row in table.find_all(\"tr\")[1:11]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    Playername.append(cols[1].text.strip())\n",
    "    Team.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "df=pd.DataFrame({'Player':Playername,'Team':Team,'Ratings': ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b3e32",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "119c1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Player Team Ratings\n",
      "1    Hayley Matthews   WI     373\n",
      "2     Natalie Sciver  ENG     371\n",
      "3       Ellyse Perry  AUS     366\n",
      "4     Marizanne Kapp   SA     349\n",
      "5        Amelia Kerr   NZ     336\n",
      "6      Deepti Sharma  IND     322\n",
      "7   Ashleigh Gardner  AUS     292\n",
      "8      Jess Jonassen  AUS     250\n",
      "9           Nida Dar  PAK     232\n",
      "10    Jhulan Goswami  IND     214\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "Playername = []\n",
    "Team = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "for row in table.find_all(\"tr\")[1:11]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    Playername.append(cols[1].text.strip())\n",
    "    Team.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "df = pd.DataFrame({\"Player\": Playername,\"Team\": Team,\"Ratings\": ratings})\n",
    "df.index = df.index + 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbccca31",
   "metadata": {},
   "source": [
    "# 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbd18d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ukraine war live updates: Wagner Group claims ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A grinding assault? What to expect from Russia...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/what-to-expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analysts see short-term strength, long-term 'g...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/analysts-see-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>European markets muted as investors assess mon...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India's largest insurer says it may review sta...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/indias-largest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNBC Daily Open: Oil popped and stocks flopped...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This corner of tech has rebounded — and strate...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/chip-stocks-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chinese EV brand Zeekr is now worth more than ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/chinese-ev-bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Moody's cuts outlook for four Adani group comp...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/moodys-cuts-ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Singapore budget expected to focus on inflatio...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/heres-what-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here are 5 ETFs that offer more than 10% yield...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/jepi-and-more-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'Play offense, not defense': Analyst says buy ...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/play-offense-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Asia markets mixed ahead of economic data rele...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/asia-markets-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNBC Daily Open: Oil popped and stocks flopped...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/13/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stock futures are down as Wall Street tries to...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/stock-market-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Investing Club mailbag: How to tell if a compa...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Super Bowl LVII: Chiefs win, Rihanna is pregna...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/super-bowl-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U.S. shoots down a fourth high-altitude object...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/members-of-con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mark Cuban: Internet misinformation will only ...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/mark-cuban-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Why a higher Social Security full retirement a...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/social-securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here's how much Americans plan to spend on the...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/super-bowl-how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Perfectionism can be your enemy, but it’s simp...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/how-to-fix-per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Meet Justina Miles, Rihanna's Super Bowl halft...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/meet-justina-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Here's where the jobs will be during the rolli...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/heres-where-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Breaking down the trade on Tesla shares ahead ...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/tesla-investor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What to know about A.I. ETFs as ChatGPT hyster...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/what-to-know-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10 stocks that fit Warren Buffett's takeover c...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/warren-buffett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Electric Ram pickup debuts in Super Bowl spot ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/12/ram-super-bowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Neuralink investigated for possible unsafe tra...</td>\n",
       "      <td>February 11, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/02/11/elon-musks-neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ChatGPT AI hype cycle is peaking, but even tec...</td>\n",
       "      <td>February 11, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/02/11/chatgpt-ai-hyp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline               Time  \\\n",
       "0   Ukraine war live updates: Wagner Group claims ...        2 Hours Ago   \n",
       "1   A grinding assault? What to expect from Russia...        2 Hours Ago   \n",
       "2   Analysts see short-term strength, long-term 'g...        3 Hours Ago   \n",
       "3   European markets muted as investors assess mon...        3 Hours Ago   \n",
       "4   India's largest insurer says it may review sta...        3 Hours Ago   \n",
       "5   CNBC Daily Open: Oil popped and stocks flopped...        3 Hours Ago   \n",
       "6   This corner of tech has rebounded — and strate...        5 Hours Ago   \n",
       "7   Chinese EV brand Zeekr is now worth more than ...        5 Hours Ago   \n",
       "8   Moody's cuts outlook for four Adani group comp...        7 Hours Ago   \n",
       "9   Singapore budget expected to focus on inflatio...        7 Hours Ago   \n",
       "10  Here are 5 ETFs that offer more than 10% yield...        8 Hours Ago   \n",
       "11  'Play offense, not defense': Analyst says buy ...        8 Hours Ago   \n",
       "12  Asia markets mixed ahead of economic data rele...       10 Hours Ago   \n",
       "13  CNBC Daily Open: Oil popped and stocks flopped...       10 Hours Ago   \n",
       "14  Stock futures are down as Wall Street tries to...       10 Hours Ago   \n",
       "15  Investing Club mailbag: How to tell if a compa...       12 Hours Ago   \n",
       "16  Super Bowl LVII: Chiefs win, Rihanna is pregna...       13 Hours Ago   \n",
       "17  U.S. shoots down a fourth high-altitude object...       17 Hours Ago   \n",
       "18  Mark Cuban: Internet misinformation will only ...       19 Hours Ago   \n",
       "19  Why a higher Social Security full retirement a...       20 Hours Ago   \n",
       "20  Here's how much Americans plan to spend on the...       20 Hours Ago   \n",
       "21  Perfectionism can be your enemy, but it’s simp...       20 Hours Ago   \n",
       "22  Meet Justina Miles, Rihanna's Super Bowl halft...       20 Hours Ago   \n",
       "23  Here's where the jobs will be during the rolli...       21 Hours Ago   \n",
       "24  Breaking down the trade on Tesla shares ahead ...       21 Hours Ago   \n",
       "25  What to know about A.I. ETFs as ChatGPT hyster...       21 Hours Ago   \n",
       "26  10 stocks that fit Warren Buffett's takeover c...       21 Hours Ago   \n",
       "27  Electric Ram pickup debuts in Super Bowl spot ...       22 Hours Ago   \n",
       "28  Neuralink investigated for possible unsafe tra...  February 11, 2023   \n",
       "29  ChatGPT AI hype cycle is peaking, but even tec...  February 11, 2023   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/02/13/ukraine-war-li...  \n",
       "1   https://www.cnbc.com/2023/02/13/what-to-expect...  \n",
       "2   https://www.cnbc.com/2023/02/13/analysts-see-s...  \n",
       "3   https://www.cnbc.com/2023/02/13/european-marke...  \n",
       "4   https://www.cnbc.com/2023/02/13/indias-largest...  \n",
       "5   https://www.cnbc.com/2023/02/13/stock-markets-...  \n",
       "6   https://www.cnbc.com/2023/02/13/chip-stocks-an...  \n",
       "7   https://www.cnbc.com/2023/02/13/chinese-ev-bra...  \n",
       "8   https://www.cnbc.com/2023/02/13/moodys-cuts-ou...  \n",
       "9   https://www.cnbc.com/2023/02/13/heres-what-to-...  \n",
       "10  https://www.cnbc.com/2023/02/13/jepi-and-more-...  \n",
       "11  https://www.cnbc.com/2023/02/13/play-offense-n...  \n",
       "12  https://www.cnbc.com/2023/02/13/asia-markets-i...  \n",
       "13  https://www.cnbc.com/2023/02/13/stock-markets-...  \n",
       "14  https://www.cnbc.com/2023/02/12/stock-market-t...  \n",
       "15  https://www.cnbc.com/2023/02/12/investing-club...  \n",
       "16  https://www.cnbc.com/2023/02/12/super-bowl-202...  \n",
       "17  https://www.cnbc.com/2023/02/12/members-of-con...  \n",
       "18  https://www.cnbc.com/2023/02/12/mark-cuban-cha...  \n",
       "19  https://www.cnbc.com/2023/02/12/social-securit...  \n",
       "20  https://www.cnbc.com/2023/02/12/super-bowl-how...  \n",
       "21  https://www.cnbc.com/2023/02/12/how-to-fix-per...  \n",
       "22  https://www.cnbc.com/2023/02/12/meet-justina-m...  \n",
       "23  https://www.cnbc.com/2023/02/12/heres-where-th...  \n",
       "24  https://www.cnbc.com/2023/02/12/tesla-investor...  \n",
       "25  https://www.cnbc.com/2023/02/12/what-to-know-a...  \n",
       "26  https://www.cnbc.com/2023/02/12/warren-buffett...  \n",
       "27  https://www.cnbc.com/2023/02/12/ram-super-bowl...  \n",
       "28  https://www.cnbc.com/2023/02/11/elon-musks-neu...  \n",
       "29  https://www.cnbc.com/2023/02/11/chatgpt-ai-hyp...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "headline = []\n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):\n",
    "    headline.append(i.text)\n",
    "time = []\n",
    "for i in soup.find_all('time',class_='LatestNews-timestamp'):\n",
    "    time.append(i.text)\n",
    "link = []\n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):\n",
    "    link.append(i.get('href'))\n",
    "df=pd.DataFrame({'Headline':headline,'Time':time,'News Link': link})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80843515",
   "metadata": {},
   "source": [
    "# 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2a2997e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "\n",
    "Authors = [] \n",
    "for i in soup.find_all(\"span\", 'sc-1w3fpd7-0 dnCnAO'):\n",
    "    Authors.append(i.text)\n",
    "pdate = []\n",
    "for i in soup.find_all('span',class_='sc-1thf9ly-2 dvggWt'):\n",
    "    pdate.append(i.text)\n",
    "title = []\n",
    "for i in soup.find_all('h2'):\n",
    "    title.append(i.text)\n",
    "purl = []\n",
    "for i in soup.find_all('a',class_='sc-5smygv-0 fIXTHm'):\n",
    "    purl.append(i.get('href'))\n",
    "df=pd.DataFrame({'Paper Title':title,'Authors':Authors,'Published Date': pdate,'Paper URL': purl,})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda33296",
   "metadata": {},
   "source": [
    "# 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "220cb018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamasha</td>\n",
       "      <td>Continental, Asian, Italian, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Local</td>\n",
       "      <td>North Indian, Asian, Continental</td>\n",
       "      <td>Scindia House,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ministry Of Beer</td>\n",
       "      <td>North Indian, Continental, American, Asian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Station Bar</td>\n",
       "      <td>Italian, Chinese, North Indian, Fast Food</td>\n",
       "      <td>F-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unplugged Courtyard</td>\n",
       "      <td>North Indian, Italian, Chinese, Turkish, Cont...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Openhouse Cafe</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Junkyard Cafe</td>\n",
       "      <td>North Indian, Continental, Chinese, Fast Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cafe Delhi Heights</td>\n",
       "      <td>Continental, North Indian, Beverages, Chinese...</td>\n",
       "      <td>Janpath, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The G.T. Road</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cafe High 5</td>\n",
       "      <td>North Indian, Continental, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dhaba Estd 1986 Delhi</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>My Bar Square</td>\n",
       "      <td>Finger Food, Chinese, Continental, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Warehouse Cafe</td>\n",
       "      <td>North Indian, Chinese, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Out Of The Box Courtyard</td>\n",
       "      <td>North Indian, Mediterranean, Chinese, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>QBA</td>\n",
       "      <td>North Indian, Continental, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dasaprakash</td>\n",
       "      <td>North Indian, South Indian, Beverages, Chines...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Somewhere Restaurant &amp; Bar</td>\n",
       "      <td>North Indian, Continental, Asian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lord of the Drinks</td>\n",
       "      <td>Chinese, North Indian, Fast Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38 Barracks</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ardor 2.1 Restaurant and Lounge</td>\n",
       "      <td>North Indian, Chinese, Italian, Continental</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chido</td>\n",
       "      <td>North Indian, Italian, Continental, Asian, Fi...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant name  \\\n",
       "0                           Tamasha   \n",
       "1                             Local   \n",
       "2                  Ministry Of Beer   \n",
       "3                       Station Bar   \n",
       "4               Unplugged Courtyard   \n",
       "5                    Openhouse Cafe   \n",
       "6                 The Junkyard Cafe   \n",
       "7                Cafe Delhi Heights   \n",
       "8                     The G.T. Road   \n",
       "9                       Cafe High 5   \n",
       "10            Dhaba Estd 1986 Delhi   \n",
       "11                    My Bar Square   \n",
       "12                   Warehouse Cafe   \n",
       "13         Out Of The Box Courtyard   \n",
       "14                              QBA   \n",
       "15                      Dasaprakash   \n",
       "16       Somewhere Restaurant & Bar   \n",
       "17               Lord of the Drinks   \n",
       "18                      38 Barracks   \n",
       "19  Ardor 2.1 Restaurant and Lounge   \n",
       "20                            Chido   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0           Continental, Asian, Italian, North Indian   \n",
       "1                    North Indian, Asian, Continental   \n",
       "2          North Indian, Continental, American, Asian   \n",
       "3           Italian, Chinese, North Indian, Fast Food   \n",
       "4    North Indian, Italian, Chinese, Turkish, Cont...   \n",
       "5                        North Indian, Asian, Italian   \n",
       "6       North Indian, Continental, Chinese, Fast Food   \n",
       "7    Continental, North Indian, Beverages, Chinese...   \n",
       "8                                        North Indian   \n",
       "9                  North Indian, Continental, Chinese   \n",
       "10                                       North Indian   \n",
       "11         Finger Food, Chinese, Continental, Italian   \n",
       "12                     North Indian, Chinese, Italian   \n",
       "13      North Indian, Mediterranean, Chinese, Italian   \n",
       "14                 North Indian, Continental, Italian   \n",
       "15   North Indian, South Indian, Beverages, Chines...   \n",
       "16                   North Indian, Continental, Asian   \n",
       "17                   Chinese, North Indian, Fast Food   \n",
       "18                 North Indian, Chinese, Continental   \n",
       "19        North Indian, Chinese, Italian, Continental   \n",
       "20   North Indian, Italian, Continental, Asian, Fi...   \n",
       "\n",
       "                                        Location Ratings  \\\n",
       "0                 Connaught Place, Central Delhi     4.2   \n",
       "1   Scindia House,Connaught Place, Central Delhi       4   \n",
       "2         M-Block,Connaught Place, Central Delhi       4   \n",
       "3         F-Block,Connaught Place, Central Delhi       4   \n",
       "4                 Connaught Place, Central Delhi       4   \n",
       "5                 Connaught Place, Central Delhi     4.1   \n",
       "6                 Connaught Place, Central Delhi     4.1   \n",
       "7                         Janpath, Central Delhi     4.3   \n",
       "8         M-Block,Connaught Place, Central Delhi     4.3   \n",
       "9                 Connaught Place, Central Delhi       4   \n",
       "10                Connaught Place, Central Delhi     4.1   \n",
       "11                Connaught Place, Central Delhi     3.9   \n",
       "12                Connaught Place, Central Delhi     4.1   \n",
       "13                Connaught Place, Central Delhi     4.1   \n",
       "14                Connaught Place, Central Delhi     4.2   \n",
       "15                Connaught Place, Central Delhi     4.2   \n",
       "16                Connaught Place, Central Delhi     4.1   \n",
       "17                Connaught Place, Central Delhi     4.2   \n",
       "18        M-Block,Connaught Place, Central Delhi     4.3   \n",
       "19                Connaught Place, Central Delhi     4.1   \n",
       "20                Connaught Place, Central Delhi     4.2   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://www.dineout.co.in/delhi-restaurants?search_str=delhi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "\n",
    "title = []\n",
    "for i in soup.find_all('a',class_='restnt-name ellipsis'):\n",
    "    title.append(i.text)\n",
    "Location = []\n",
    "for i in soup.find_all('div', class_='restnt-loc ellipsis'):\n",
    "    Location.append(i.text)\n",
    "ratings = []\n",
    "for i in soup.find_all('div', class_='restnt-rating rating-4'):\n",
    "    ratings.append(i.text)\n",
    "images = []\n",
    "for i in soup.find_all('img',class_='no-img'):\n",
    "    images.append(i.get('data-src'))\n",
    "cuisine = [] \n",
    "for i in soup.find_all(\"span\", 'double-line-ellipsis'):\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "df=pd.DataFrame({'Restaurant name':title,'Cuisine':cuisine,'Location': Location,'Ratings': ratings,'Image URL': images})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c6f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
